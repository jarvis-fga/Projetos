{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics as st\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa as parada tudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/SCDB_Legacy_01_justiceCentered_Citation.csv', encoding=\"ISO-8859-1\", nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = data['caseDisposition'] # saida\n",
    "out = []\n",
    "\n",
    "for case in disp:\n",
    "    if case == 2.0:\n",
    "        out.append(0) #affirmative\n",
    "    elif case == 3.0 or case == 4.0:\n",
    "        out.append(1) #reverse\n",
    "    else:\n",
    "        out.append(2) #Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop irrelevant columns\n",
    "data = data.drop(['caseDisposition',\n",
    "                  'caseId',\n",
    "                  'docketId',\n",
    "                  'caseIssuesId',\n",
    "                  'voteId',\n",
    "                  'caseName',\n",
    "                  'usCite',\n",
    "                  'sctCite',\n",
    "                  'ledCite'],\n",
    "                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with more than 25% of NaN\n",
    "data = data.loc[:, (data.isnull().sum() <= len(data) * 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifies if column has strings\n",
    "def has_no_strings (col):\n",
    "    for row in col:\n",
    "        if type(row) is str:\n",
    "            print('\"{}\" is string'.format(row))\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dateDecision\n",
      "\"8/3/1791\" is string\n",
      "decisionType\n",
      "non-string\n",
      "\n",
      "lexisCite\n",
      "\"1791 U.S. LEXIS 189\" is string\n",
      "term\n",
      "non-string\n",
      "\n",
      "naturalCourt\n",
      "non-string\n",
      "\n",
      "chief\n",
      "\"Jay\" is string\n",
      "dateArgument\n",
      "\"8/2/1791\" is string\n",
      "petitioner\n",
      "non-string\n",
      "\n",
      "respondent\n",
      "non-string\n",
      "\n",
      "jurisdiction\n",
      "non-string\n",
      "\n",
      "threeJudgeFdc\n",
      "non-string\n",
      "\n",
      "caseOrigin\n",
      "non-string\n",
      "\n",
      "caseSource\n",
      "non-string\n",
      "\n",
      "lcDisagreement\n",
      "non-string\n",
      "\n",
      "certReason\n",
      "non-string\n",
      "\n",
      "lcDispositionDirection\n",
      "non-string\n",
      "\n",
      "declarationUncon\n",
      "non-string\n",
      "\n",
      "caseDispositionUnusual\n",
      "non-string\n",
      "\n",
      "partyWinning\n",
      "non-string\n",
      "\n",
      "precedentAlteration\n",
      "non-string\n",
      "\n",
      "voteUnclear\n",
      "non-string\n",
      "\n",
      "issue\n",
      "non-string\n",
      "\n",
      "issueArea\n",
      "non-string\n",
      "\n",
      "decisionDirection\n",
      "non-string\n",
      "\n",
      "decisionDirectionDissent\n",
      "non-string\n",
      "\n",
      "authorityDecision1\n",
      "non-string\n",
      "\n",
      "lawType\n",
      "non-string\n",
      "\n",
      "lawSupp\n",
      "non-string\n",
      "\n",
      "majOpinWriter\n",
      "non-string\n",
      "\n",
      "majOpinAssigner\n",
      "non-string\n",
      "\n",
      "splitVote\n",
      "non-string\n",
      "\n",
      "majVotes\n",
      "non-string\n",
      "\n",
      "minVotes\n",
      "non-string\n",
      "\n",
      "justice\n",
      "non-string\n",
      "\n",
      "justiceName\n",
      "\"JJay\" is string\n",
      "vote\n",
      "non-string\n",
      "\n",
      "opinion\n",
      "non-string\n",
      "\n",
      "direction\n",
      "non-string\n",
      "\n",
      "majority\n",
      "non-string\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# where the program finds only numbers, input mean on NaN values\n",
    "for col in data:\n",
    "    print(col)\n",
    "    if has_no_strings(data[col]):\n",
    "        print('non-string\\n')\n",
    "        data[col].fillna((data[col].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vetorizar_texto(cell, mapa):   #transformar palavras em vetores\n",
    "    vetor = [0] * len(mapa)\n",
    "    if cell in mapa:\n",
    "        posicao = mapa[cell]\n",
    "        # print(posicao)\n",
    "        vetor[posicao] = 1\n",
    "    return vetor\n",
    "\n",
    "def vetoriza_string (col):\n",
    "    dicionario = []\n",
    "    for cell in col:  #colocar cada palavra encontrada no conjunto\n",
    "        if (cell not in dicionario and\n",
    "            cell != 'NULL' and\n",
    "            cell != 'unknown' and\n",
    "            cell != np.nan and\n",
    "            cell != 'unidentifiable'):    # Criando um conjunto sem repetições\n",
    "            dicionario.append(cell)\n",
    "    total = len(dicionario)   #salvar o número de palavras catalogadas no conjunto\n",
    "    # print(dicionario)\n",
    "    # print(total)\n",
    "    tuplas = zip(dicionario, range(total))    #dar um índice a cada palavra encontrada\n",
    "    mapa = {palavra:indice for palavra, indice in tuplas}   #criar um DICIONARIO capaz de retornar o índice de determinada palavra\n",
    "\n",
    "    vcol = []\n",
    "    for cell in col:\n",
    "        vcol.append(vetorizar_texto(cell, mapa))\n",
    "    return vcol\n",
    "\n",
    "def vetoriza_data (col):\n",
    "    datelist = []\n",
    "    for cell in col:\n",
    "        try:\n",
    "            dt = datetime.strptime(cell, '%m/%d/%Y')\n",
    "            day = dt.strftime('%j')\n",
    "            datelist.append([day, dt.year])\n",
    "        except:\n",
    "            datelist.append([-1, -1])\n",
    "    return datelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiefs = np.array(vetoriza_string(data['chief']))\n",
    "justice = np.array(vetoriza_string(data['justiceName']))\n",
    "lexis = np.array(vetoriza_string(data['lexisCite']))\n",
    "dtDecision = np.array(vetoriza_data(data['dateDecision']))\n",
    "dtArgument = np.array(vetoriza_data(data['dateArgument']))\n",
    "# dtRearg = np.array(vetoriza_data(data['dateRearg']))\n",
    "# minor = np.array(vetoriza_string(data['lawMinor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['chief',\n",
    "                  'justiceName',\n",
    "                  'lexisCite',\n",
    "                  'dateDecision',\n",
    "                  'dateArgument',\n",
    "                  #'dateRearg',\n",
    "                  #'lawMinor'\n",
    "                  ],\n",
    "                 axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data)\n",
    "X = np.concatenate((X,\n",
    "                    chiefs,\n",
    "                    justice,\n",
    "                    lexis,\n",
    "                    dtDecision,\n",
    "                    dtArgument,\n",
    "                    #dtRearg,\n",
    "                    #minor\n",
    "                    ),\n",
    "                   axis=1)\n",
    "Y = np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(float)\n",
    "\n",
    "porcentagem_de_treino = 0.8\n",
    "tamanho_do_treino = int(porcentagem_de_treino * len(Y))\n",
    "tamanho_de_validacao = len(Y) - tamanho_do_treino\n",
    "\n",
    "treino_dados = X[0:tamanho_do_treino]\n",
    "treino_marcacoes = Y[0:tamanho_do_treino]\n",
    "\n",
    "validacao_dados = X[tamanho_do_treino:]\n",
    "validacao_marcacoes = Y[tamanho_do_treino:]\n",
    "\n",
    "modelo = linear_model.SGDClassifier()\n",
    "resultadoModelo = treinarePrever(\"SGDClassifier\", modelo, treino_dados, treino_marcacoes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
