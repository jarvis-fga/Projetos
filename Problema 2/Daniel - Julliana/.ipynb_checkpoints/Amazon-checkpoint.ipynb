{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, é necessária a leitura dos 3 arquivos, inserindo as informações em um vetor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "with codecs.open(\"imdb_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    vetor = []\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)\n",
    "with codecs.open(\"amazon_cells_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)\n",
    "with codecs.open(\"yelp_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, devemos retirar cada quebra de linha no final de cada linha, ou seja, os '\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vetor = [ x[:-1] for x in vetor ]\n",
    "\n",
    "import nltk\n",
    "\n",
    "vetor = ([s.replace('&', '').replace(' - ', '').replace('.', '').replace(',', '').replace('!', '').\n",
    "          replace('+', '')for s in vetor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, retiramos os dois últimos caracteres sobrando apenas o nosso comentário. Depois, passamos ele para lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TextosQuebrados = [ x[:-4] for x in vetor ]\n",
    "\n",
    "TextosQuebrados = map(lambda X:X.lower(),TextosQuebrados)\n",
    "\n",
    "#TextosQuebrados = [x.split(' ') for x in TextosQuebrados]\n",
    "\n",
    "TextosQuebrados = [nltk.tokenize.word_tokenize(frase) for frase in TextosQuebrados]\n",
    "\n",
    "#X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "dicionario = set()\n",
    "\n",
    "for comentarios in TextosQuebrados:\n",
    "    validas = [stemmer.stem(palavra) for palavra in comentarios if palavra not in stopwords and len(palavra) > 0]\n",
    "    dicionario.update(validas)\n",
    "\n",
    "    \n",
    "totalDePalavras = len(dicionario)\n",
    "tuplas = zip(dicionario, xrange(totalDePalavras))\n",
    "tradutor = {palavra:indice for palavra,indice in tuplas}\n",
    "        \n",
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "\n",
    "    return vetor\n",
    "\n",
    "vetoresDeTexto = [vetorizar_texto(texto, tradutor,stemmer) for texto in TextosQuebrados]\n",
    "X = vetoresDeTexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3002"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = [ x[-1:] for x in vetor ]\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porcentagem_de_treino = 0.8\n",
    "\n",
    "tamanho_do_treino = porcentagem_de_treino * len(Y)\n",
    "tamanho_de_validacao = len(Y) - tamanho_do_treino\n",
    "\n",
    "treino_dados = X[0:int(tamanho_do_treino)]\n",
    "treino_marcacoes = Y[0:int(tamanho_do_treino)]\n",
    "\n",
    "validacao_dados = X[int(tamanho_do_treino):]\n",
    "validacao_marcacoes = Y[int(tamanho_do_treino):]\n",
    "\n",
    "fim_de_teste = tamanho_do_treino + tamanho_de_validacao\n",
    "teste_dados = X[int(tamanho_do_treino):int(fim_de_teste)]\n",
    "teste_marcacoes = Y[int(tamanho_do_treino):int(fim_de_teste)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi decidida a abordagem por poly SCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-8-ec94ce357cd1>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-ec94ce357cd1>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    print('poly_svc: ', accuracy_poly_svc.mean())\"\"\"\"\u001b[0m\n\u001b[0m                                                     \n^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k = 10\n",
    "\n",
    "# Implement poly SVC \n",
    "poly_svc = svm.SVC(kernel='linear')\n",
    "accuracy_poly_svc = cross_val_score(poly_svc, treino_dados, treino_marcacoes, cv=k, scoring='accuracy')\n",
    "print('poly_svc: ', accuracy_poly_svc.mean())\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado - Poly: \n",
    "\n",
    "Os 3: Após 10 minutos rodando, foi decidido parar o teste\n",
    "\n",
    "IMdB: 0.51750234411626805\n",
    "\n",
    "Amazon: 0.51125019534302241\n",
    "\n",
    "Yelp: 0.56500429754649173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado - Linear:\n",
    "\n",
    "Os 3: 0.7745982496802607 (5 minutos)\n",
    "\n",
    "IMdB: 0.72168288013752147\n",
    "\n",
    "Amazon: 0.78869745272698855\n",
    "\n",
    "Yelp: 0.77492342553523996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.527454242928\n"
     ]
    }
   ],
   "source": [
    "def fit_and_predict(nome, modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "\tmodelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "\tresultado = modelo.predict(teste_dados)\n",
    "\tacertos = (resultado == teste_marcacoes)\n",
    "\n",
    "\ttotal_de_acertos = sum(acertos)\n",
    "\ttotal_de_elementos = len(teste_dados)\n",
    "\ttaxa_de_acerto = float(total_de_acertos) / float(total_de_elementos)\n",
    "\n",
    "\tprint(taxa_de_acerto)\n",
    "\treturn taxa_de_acerto\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "resultadoMultinomial = fit_and_predict(\"MultinomialNB\", AdaBoostClassifier(n_estimators=100), treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB:\n",
    "\n",
    "Todos: 0.811666666667\n",
    "\n",
    "IMDB: 0.775\n",
    "\n",
    "Amazon: 76.5\n",
    "\n",
    "Yell: 0.715"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com maior refinamento de dados:\n",
    "\n",
    "MultinomialNB:\n",
    "\n",
    "Todos: 0.808652246256\n",
    "\n",
    "Adaboost:\n",
    "\n",
    "Todos:0.527454242928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
