{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, é necessária a leitura dos 3 arquivos, inserindo as informações em um vetor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "with codecs.open(\"imdb_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    vetor = []\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)\n",
    "with codecs.open(\"amazon_cells_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)\n",
    "with codecs.open(\"yelp_labelled.txt\", \"r\",  \"utf-8\") as arquivo:\n",
    "    for linha in arquivo:\n",
    "        vetor.append(linha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois, devemos retirar cada quebra de linha no final de cada linha, ou seja, os '\\n'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vetor = [ x[:-1] for x in vetor ]\n",
    "\n",
    "vetor = ([s.replace('&', '').replace(' - ', '').replace('.', '').replace(',', '').replace('!', '').\n",
    "          replace('+', '')for s in vetor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, retiramos os dois últimos caracteres sobrando apenas o nosso comentário. Depois, passamos ele para lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2ce741fc3871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#TextosQuebrados = [x.split(' ') for x in TextosQuebrados]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mTextosQuebrados\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrase\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTextosQuebrados\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "TextosQuebrados = [ x[:-4] for x in vetor ]\n",
    "\n",
    "TextosQuebrados = map(lambda X:X.lower(),TextosQuebrados)\n",
    "\n",
    "#TextosQuebrados = [x.split(' ') for x in TextosQuebrados]\n",
    "\n",
    "TextosQuebrados = [nltk.tokenize.word_tokenize(frase) for frase in TextosQuebrados]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "dicionario = set()\n",
    "\n",
    "for comentarios in TextosQuebrados:\n",
    "    validas = [stemmer.stem(palavra) for palavra in comentarios if palavra not in stopwords and len(palavra) > 0]\n",
    "    dicionario.update(validas)\n",
    "\n",
    "    \n",
    "totalDePalavras = len(dicionario)\n",
    "tuplas = zip(dicionario, xrange(totalDePalavras))\n",
    "tradutor = {palavra:indice for palavra,indice in tuplas}\n",
    "        \n",
    "def vetorizar_texto(texto, tradutor, stemmer):\n",
    "    vetor = [0] * len(tradutor)\n",
    "    for palavra in texto:\n",
    "        if len(palavra) > 0:\n",
    "            raiz = stemmer.stem(palavra)\n",
    "            if raiz in tradutor:\n",
    "                posicao = tradutor[raiz]\n",
    "                vetor[posicao] += 1\n",
    "\n",
    "    return vetor\n",
    "\n",
    "vetoresDeTexto = [vetorizar_texto(texto, tradutor,stemmer) for texto in TextosQuebrados]\n",
    "X = vetoresDeTexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = [ x[-1:] for x in vetor ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porcentagem_de_treino = 0.8\n",
    "\n",
    "tamanho_do_treino = porcentagem_de_treino * len(Y)\n",
    "tamanho_de_validacao = len(Y) - tamanho_do_treino\n",
    "\n",
    "treino_dados = X[0:int(tamanho_do_treino)]\n",
    "treino_marcacoes = Y[0:int(tamanho_do_treino)]\n",
    "\n",
    "validacao_dados = X[int(tamanho_do_treino):]\n",
    "validacao_marcacoes = Y[int(tamanho_do_treino):]\n",
    "\n",
    "fim_de_teste = tamanho_do_treino + tamanho_de_validacao\n",
    "teste_dados = X[int(tamanho_do_treino):int(fim_de_teste)]\n",
    "teste_marcacoes = Y[int(tamanho_do_treino):int(fim_de_teste)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi decidida a abordagem por poly SCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" from sklearn import svm\\nfrom sklearn.model_selection import cross_val_score\\nk = 10\\n\\n# Implement poly SVC \\npoly_svc = svm.SVC(kernel='linear')\\naccuracy_poly_svc = cross_val_score(poly_svc, treino_dados, treino_marcacoes, cv=k, scoring='accuracy')\\nprint('poly_svc: ', accuracy_poly_svc.mean()) \""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k = 10\n",
    "\n",
    "# Implement poly SVC \n",
    "poly_svc = svm.SVC(kernel='linear')\n",
    "accuracy_poly_svc = cross_val_score(poly_svc, treino_dados, treino_marcacoes, cv=k, scoring='accuracy')\n",
    "print('poly_svc: ', accuracy_poly_svc.mean()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado - Poly: \n",
    "\n",
    "Os 3: Após 10 minutos rodando, foi decidido parar o teste\n",
    "\n",
    "IMdB: 0.51750234411626805\n",
    "\n",
    "Amazon: 0.51125019534302241\n",
    "\n",
    "Yelp: 0.56500429754649173"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado - Linear:\n",
    "\n",
    "Os 3: 0.7745982496802607 (5 minutos)\n",
    "\n",
    "IMdB: 0.72168288013752147\n",
    "\n",
    "Amazon: 0.78869745272698855\n",
    "\n",
    "Yelp: 0.77492342553523996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.618968386023\n"
     ]
    }
   ],
   "source": [
    "def fit_and_predict(modelo, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes):\n",
    "\tmodelo.fit(treino_dados, treino_marcacoes)\n",
    "\n",
    "\tresultado = modelo.predict(teste_dados)\n",
    "\tacertos = (resultado == teste_marcacoes)\n",
    "\n",
    "\ttotal_de_acertos = sum(acertos)\n",
    "\ttotal_de_elementos = len(teste_dados)\n",
    "\ttaxa_de_acerto = float(total_de_acertos) / float(total_de_elementos)\n",
    "\n",
    "\tprint(taxa_de_acerto)\n",
    "\treturn taxa_de_acerto\n",
    "\n",
    "\n",
    "resultados = {}\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "modeloMultinomial = MultinomialNB()\n",
    "\n",
    "resultadoMultinomial = fit_and_predict(modeloMultinomial, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n",
    "resultados[resultadoMultinomial] = modeloMultinomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com maior refinamento de dados:\n",
    "\n",
    "MultinomialNB:\n",
    "\n",
    "Todos: 0.808652246256\n",
    "\n",
    "Adaboost:\n",
    "\n",
    "Todos:0.527454242928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996672212978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "classificador = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(treino_dados, treino_marcacoes)\n",
    "resultado = fit_and_predict(classificador, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier:\n",
    "\n",
    "Todos: 0.77870216306156403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "classificador = GaussianNB()\n",
    "resultado = fit_and_predict(classificador, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussiano:\n",
    "\n",
    "0.665557404326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801996672213\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classificador = BernoulliNB()\n",
    "resultado = fit_and_predict(classificador, treino_dados, treino_marcacoes, teste_dados, teste_marcacoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli: 0.801996672213"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
